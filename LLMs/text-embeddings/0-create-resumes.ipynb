{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a439429c-46eb-40be-a62b-4c90855f2023",
      "metadata": {
        "id": "a439429c-46eb-40be-a62b-4c90855f2023"
      },
      "source": [
        "# Generate Synthetic Dataset for Text Embedding Use Cases\n",
        "\n",
        "Code authored by: Shaw Talebi <br>\n",
        "Article link: https://towardsdatascience.com/text-embeddings-classification-and-semantic-search-8291746220be <br>\n",
        "Video link: https://youtu.be/sNa_uiqSlJo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c83085a-9f2b-42fb-97e6-af96ba98edc7",
      "metadata": {
        "id": "4c83085a-9f2b-42fb-97e6-af96ba98edc7"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: set the OPENAI api key environment variable\n",
        "\n",
        "# # Generate Synthetic Dataset for Text Embedding Use Cases\n",
        "#\n",
        "# Code authored by: Shaw Talebi <br>\n",
        "# Article link: https://towardsdatascience.com/text-embeddings-classification-and-semantic-search-8291746220be <br>\n",
        "# Video link: https://youtu.be/sNa_uiqSlJo\n",
        "# ### imports\n",
        "\n",
        "from google.colab import userdata\n",
        "openaikey = userdata.get('OPENAI')\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = openaikey"
      ],
      "metadata": {
        "id": "p563AZgYkROj"
      },
      "id": "p563AZgYkROj",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b9f1345a-e766-4a7d-9989-7859b2f31763",
      "metadata": {
        "id": "b9f1345a-e766-4a7d-9989-7859b2f31763"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import time\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5c57a735-e1a7-46d4-b88e-b19455bb507b",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "5c57a735-e1a7-46d4-b88e-b19455bb507b"
      },
      "outputs": [],
      "source": [
        "def wait_for_assistant(thread, run):\n",
        "    \"\"\"\n",
        "        Function to periodically check run status of AI assistant and print run time\n",
        "    \"\"\"\n",
        "\n",
        "    # wait for assistant process prompt\n",
        "    t0 = time.time()\n",
        "    while run.status != 'completed':\n",
        "\n",
        "        # retreive status of run (this might take a few seconds or more)\n",
        "        run = client.beta.threads.runs.retrieve(\n",
        "          thread_id=thread.id,\n",
        "          run_id=run.id\n",
        "        )\n",
        "\n",
        "        # wait 0.5 seconds\n",
        "        time.sleep(0.25)\n",
        "    dt = time.time() - t0\n",
        "    print(\"Elapsed time: \" + str(dt) + \" seconds\")\n",
        "\n",
        "    return run"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a208ff2d-5ce4-4d99-81cb-205d1e842f4e",
      "metadata": {
        "id": "a208ff2d-5ce4-4d99-81cb-205d1e842f4e"
      },
      "source": [
        "### create resume generator assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a72fb816-80fd-468c-b9ce-bafe47f58d11",
      "metadata": {
        "id": "a72fb816-80fd-468c-b9ce-bafe47f58d11"
      },
      "outputs": [],
      "source": [
        "# setup communication with API\n",
        "client = openai.OpenAI(api_key=openaikey)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1e3b0e87-98b5-497e-9962-49e3bda19306",
      "metadata": {
        "id": "1e3b0e87-98b5-497e-9962-49e3bda19306"
      },
      "outputs": [],
      "source": [
        "# define instruction string\n",
        "intstructions_string = \"\"\"ResumeGenerator is designed as an input-output system with minimal interaction. \\\n",
        "It focuses on creating fake resumes in a neutral and professional tone, covering specified sections: names, summary, professional experience, education, technical skills, certifications, awards, and honors. \\\n",
        "It creates fictional resumes based on the user's description. It never asks for more details and uses its best judgment to fill in any gaps in user requests. \\\n",
        "Providing straightforward, efficient service with little back-and-forth communication.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4632c9a9-43c2-48e5-9f74-b41c94603e53",
      "metadata": {
        "id": "4632c9a9-43c2-48e5-9f74-b41c94603e53"
      },
      "outputs": [],
      "source": [
        "# create ai assistant\n",
        "assistant = client.beta.assistants.create(\n",
        "    name=\"ResumeGenerator\",\n",
        "    instructions=intstructions_string,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "479c9233-00c0-44b3-a361-c721e0b98d30",
      "metadata": {
        "id": "479c9233-00c0-44b3-a361-c721e0b98d30"
      },
      "source": [
        "### generate resumes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c3e901c0-1449-480f-89ae-73556ecb2c1e",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "c3e901c0-1449-480f-89ae-73556ecb2c1e"
      },
      "outputs": [],
      "source": [
        "def generateResume(user_message):\n",
        "    \"\"\"\n",
        "        Function to generate fake resume based on user description.\n",
        "    \"\"\"\n",
        "\n",
        "    # create thread (i.e. object that handles conversations between user and assistant)\n",
        "    thread = client.beta.threads.create()\n",
        "\n",
        "    # add a user message to the thread\n",
        "    message = client.beta.threads.messages.create(\n",
        "        thread_id=thread.id,\n",
        "        role=\"user\",\n",
        "        content=user_message\n",
        "    )\n",
        "\n",
        "    # send message to assistant to generate a response\n",
        "    run = client.beta.threads.runs.create(\n",
        "      thread_id=thread.id,\n",
        "      assistant_id=assistant.id,\n",
        "    )\n",
        "\n",
        "    # wait for assistant process prompt\n",
        "    run = wait_for_assistant(thread, run)\n",
        "\n",
        "    # view messages added to thread\n",
        "    messages = client.beta.threads.messages.list(\n",
        "      thread_id=thread.id\n",
        "    )\n",
        "\n",
        "    return messages.data[0].content[0].text.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "400d5745-9884-4bce-a368-30470ef24bbc",
      "metadata": {
        "id": "400d5745-9884-4bce-a368-30470ef24bbc",
        "outputId": "8351ebfa-3fba-4ae3-c7f9-d482f91e1537",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 3.477494478225708 seconds\n",
            "Elapsed time: 4.735748052597046 seconds\n",
            "Elapsed time: 4.625480890274048 seconds\n",
            "Elapsed time: 6.217395782470703 seconds\n",
            "Elapsed time: 6.919778347015381 seconds\n",
            "Elapsed time: 4.1765642166137695 seconds\n",
            "Elapsed time: 4.4585771560668945 seconds\n",
            "Elapsed time: 5.019984483718872 seconds\n",
            "Elapsed time: 3.444514751434326 seconds\n",
            "Elapsed time: 5.500800371170044 seconds\n",
            "Elapsed time: 5.2902421951293945 seconds\n",
            "Elapsed time: 4.1051294803619385 seconds\n"
          ]
        }
      ],
      "source": [
        "# create fake resumes based on various data/AI roles\n",
        "\n",
        "# define dataset names\n",
        "dataset_name_list = [\"train\", \"test\"]\n",
        "\n",
        "# define role descriptions to pass to ai assistant and number of resumes to generate for each\n",
        "description_list = [\"Data Scientist\", \"Data Engineer\", \"Machine Learning Engineer\", \"AI Consultant\", \"Data Entrepreneur\", \"Generate a random resume, you decide the roles and industry.\"]\n",
        "count_list = [1,1,1,1,1,1]\n",
        "\n",
        "for dataset_name in dataset_name_list:\n",
        "    # initialize dict to store resume and role data\n",
        "    resume_dict = {'resume':[], 'role':[]}\n",
        "\n",
        "    if dataset_name == \"test\":\n",
        "        count_list = [1,1,1,1,1,1]\n",
        "\n",
        "    for i in range(len(description_list)):\n",
        "        description = description_list[i]\n",
        "        for j in range(count_list[i]):\n",
        "            resume_dict['resume'].append(generateResume(description))\n",
        "            if i==len(description_list):\n",
        "                description = \"Random\"\n",
        "            resume_dict['role'].append(description)\n",
        "\n",
        "\n",
        "    # store resumes in dataframe\n",
        "    df_resume = pd.DataFrame.from_dict(resume_dict)\n",
        "    # save dataframe as csv\n",
        "    df_resume.to_csv('resumes/resumes_'+dataset_name+'.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}